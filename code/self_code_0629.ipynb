{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from category_encoders import MEstimateEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_df=pd.read_csv('..\\input\\sample_submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,tgt_slide_d=28, train_period=28*5, feature_range=0):\n",
    "        '''\n",
    "        d1~d1913為訓練資料，共1913天，原始特徵提供。\n",
    "        d1914~1941為驗證，共28天，應該是比賽結束後釋出。\n",
    "        d1942~d1966為測試，共28天，隱藏起來的資料範圍。\n",
    "        故訓練時應該用~D1885預測D1886~D1913\n",
    "          驗證時應該用~D1913預測D1914~D1941\n",
    "          測試時應該用~D1941預測D1942~D1966\n",
    "          這樣驗證水準才會最近似於預測水準\n",
    "        \n",
    "        但若這樣會犧牲掉很多的資料，故若針對預測不同天的未來準備不同的資料會能使用到更近期的資料去訓練\n",
    "        ex 預測下一天的資料可用~d1912預測~d1913\n",
    "           預測下兩天的資料可用~d1911預測~d1913依此類推\n",
    "        '''\n",
    "        val_csv='..\\input\\sales_train_validation.csv'\n",
    "        eval_csv='..\\input\\sales_train_evaluation.csv'\n",
    "        sample_sub_csv='..\\input\\sample_submission.csv'   \n",
    "\n",
    "        # val_df_id, val_df_d_sales = self.preprocess(val_csv) # 讀取資料\n",
    "        # eval_df_id, eval_df_d_sales = self.preprocess(eval_csv) # 讀取資料\n",
    "\n",
    "        val_data, val_id_org_col, val_id_onehot_col, val_d_sales_col = self.preprocess(val_csv) # 讀取資料\n",
    "        eval_data, eval_id_org_col, eval_id_onehot_col, eval_d_sales_col = self.preprocess(eval_csv) # 讀取資料\n",
    "\n",
    "\n",
    "        sample_sub_df=pd.read_csv(sample_sub_csv,index_col=0)\n",
    "\n",
    "        # all_df_id = pd.concat([val_df_id,eval_df_id], axis=0)\n",
    "        # all_df_d_sales = pd.concat([val_df_d_sales,eval_df_d_sales], axis=0)\n",
    "        # sample_sub_df_id =all_df_id.loc(sample_sub_df.index)\n",
    "        # sample_sub_df_sales = all_df_id.loc(sample_sub_df.index)\n",
    "        \n",
    "        #確認sliding window的測試資料會有多少個\n",
    "        tgt_number = train_period//tgt_slide_d\n",
    "        #計算出最早的tgt與最晚的tgt的時間差幾天\n",
    "        real_train_period = (tgt_number-1)*tgt_slide_d\n",
    "        #計算出最多一筆資料能使用多少長度的特徵，資料總長度減去實際的training基期的資料範圍，再減去使用的模型loop。\n",
    "        max_feature_usage = 1913 - real_train_period - 28\n",
    "        if feature_range > max_feature_usage:\n",
    "            Exception('feature_range>max_feature_usage')\n",
    "        elif feature_range==0:\n",
    "            feature_range = max_feature_usage\n",
    "\n",
    "        # self.df_train = val_df_d_sales.iloc[:,:-28]\n",
    "        # self.df_val =  eval_df_d_sales.iloc[:,:-28]\n",
    "        \n",
    "        def get_data(tgt_d:int, df:pd.DataFrame, id_org_col:list, id_onehot_col:list, d_sales_col:list, is_eval=False):\n",
    "            \n",
    "            # print(id_onehot_col)\n",
    "            if not is_eval:\n",
    "                keys = df.index.to_list()\n",
    "                values = [x+f'tgt_date_{tgt_d}' for x in df.index.to_list()]\n",
    "                my_dict = dict(zip(keys, values))\n",
    "                df = df.rename(index=my_dict)     \n",
    "                df_sales = df[d_sales_col]                \n",
    "                '''y'''\n",
    "                if tgt_d==0:\n",
    "                    y = df_sales.iloc[:,-28:]\n",
    "                else:\n",
    "                    y = df_sales.iloc[:,-28-tgt_d:-tgt_d]\n",
    "                y.columns=[f'F{i+1}' for i in range(y.shape[1])]\n",
    "                '''X'''                \n",
    "                X = df_sales.iloc[:,-28-tgt_d-feature_range:-28-tgt_d]\n",
    "                tgt_d = X.columns.to_list()[-1]\n",
    "                \n",
    "            else:\n",
    "                '''y'''\n",
    "                y = ''\n",
    "\n",
    "                '''X''' \n",
    "                df_sales = df[d_sales_col]                 \n",
    "                X = df_sales.iloc[:,-feature_range:]\n",
    "                tgt_d = X.columns.to_list()[-1]                            \n",
    "                \n",
    "            \n",
    "            #更改欄位名稱為前幾天\n",
    "            \n",
    "            X.columns=[f'Previous_Day_{i}' for i in range(X.shape[1],0,-1)]\n",
    "            # print(X.head())\n",
    "            # print(df.head())\n",
    "            # df.reindex(columns=id_onehot_col)\n",
    "            X=pd.concat([X,df[id_onehot_col]],axis=1)\n",
    "            return X,y\n",
    "\n",
    "        def get_x(is_train=False):\n",
    "            pass\n",
    "\n",
    "        self.X_train=pd.DataFrame()\n",
    "        self.y_train=pd.DataFrame()\n",
    "        for tgt_d in range(0,train_period,tgt_slide_d):\n",
    "            X_tmp,y_tmp = get_data(tgt_d, val_data, val_id_org_col, val_id_onehot_col, val_d_sales_col)\n",
    "            \n",
    "            self.X_train=pd.concat([self.X_train,X_tmp],axis=0)\n",
    "            self.y_train=pd.concat([self.y_train,y_tmp],axis=0)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        self.X_val,self.y_val = get_data(0,eval_data, eval_id_org_col, eval_id_onehot_col, eval_d_sales_col)\n",
    "            \n",
    "        # self.X_train = val_df_d_sales.iloc[:,:-28]\n",
    "        # self.X_train.columns=[f'D_{i}' for i in range(self.X_train.shape[1])]\n",
    "        # self.y_train = val_df_d_sales.iloc[:,-28:]\n",
    "        \n",
    "        # self.X_val = eval_df_d_sales.iloc[:,28:-28]\n",
    "        # self.X_val.columns=[f'D_{i}' for i in range(self.X_val.shape[1])]\n",
    "        # self.y_val = eval_df_d_sales.iloc[:,-28:]\n",
    "        self.X_val_test, _ = get_data(0, val_data, val_id_org_col, val_id_onehot_col, val_d_sales_col,is_eval=True)\n",
    "        self.X_eval_test, _ = get_data(0, eval_data, eval_id_org_col, eval_id_onehot_col, eval_d_sales_col,is_eval=True)\n",
    "        \n",
    "        self.X_test = pd.concat([self.X_val_test, self.X_eval_test],axis=0)\n",
    "        # self.X_test =X_all.reindex(sample_sub_df.index.to_list())\n",
    "\n",
    "        # self.X_train = self.concat(self.X_train, val_df_id)\n",
    "        # self.X_val = self.concat(self.X_val, eval_df_id)\n",
    "\n",
    "        # all_id=pd.concat([val_df_id,eval_df_id],axis=0)\n",
    "        # self.X_test = self.concat(self.X_test, all_id.loc[sample_sub_df.index.to_list()])\n",
    "\n",
    "\n",
    "        # self.X_train, self.X_local_val, self.y_train, self.y_local_val = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # self.sales = pd.read_csv(submission_csv,index_col=0)\n",
    "        # self._sales_processed = (\n",
    "        #     sales\n",
    "        #     .drop([\"警示編號\", \"監控層級\", \"觸發說明\"], axis=1)\n",
    "        #     .assign(**sales.資料日期.dt.isocalendar(),\n",
    "        #             month=sales.資料日期.dt.month,\n",
    "        #             quarter=sales.資料日期.dt.quarter,\n",
    "        #             hfy=sales.資料日期.dt.quarter.isin([3, 4])+1,\n",
    "        #             bigMon=sales.資料日期.dt.month.isin([1, 3, 5, 7, 8, 10, 12]).astype(int))  # 將sales整理出更多的特徵資料\n",
    "        # )\n",
    "        # self.txn_c = txn[txn['tran_type'] == 'DEBIT'].drop(\"tran_type\", axis=1)\n",
    "        # self.txn_d = txn[txn['tran_type'] ==\n",
    "        #                  'CREDIT'].drop(\"tran_type\", axis=1)\n",
    "        # self.txn_t = txn[txn['tran_type'] == 'TXN'].drop(\"tran_type\", axis=1)\n",
    "\n",
    "        # self._txn_processed = txn  # _get_data_from_sql整理出的txn資料\n",
    "        # self._risk_processed = risk  # _get_data_from_sql整理出的risk資料\n",
    "        # self._info_processed = info  # _get_data_from_sql整理出的info資料\n",
    "        # self.ac = ac  # _get_data_from_sql從VW_NP_FSC_PARTY_ACCOUNT_BRIDGE整理出的客帳戶對照\n",
    "\n",
    "        # self.train = self._get_data(\"train\")  # VIP訓練資料\n",
    "        # self.val = self._get_data(\"val\")  # VIP驗證資料\n",
    "        # self.test = self._get_data(\"test\")  # VIP當天資料\n",
    "\n",
    "        # self.seg_mapping = self._get_cust_seg_def()\n",
    "\n",
    "    def preprocess(self,file_name):\n",
    "        data = pd.read_csv(file_name,index_col=0) # 讀取資料\n",
    "        id_org_col = data.iloc[:,:5].columns.to_list()\n",
    "        d_sales_col = data.iloc[:,5:].columns.to_list()\n",
    "        data_col_onehot = self._preprocess_obj_feature(data[id_org_col])\n",
    "        id_onehot_col = data_col_onehot.columns.to_list()\n",
    "        data=self.concat(data,data_col_onehot)\n",
    "        return data, id_org_col, id_onehot_col, d_sales_col\n",
    "    \n",
    "    def concat(self, X_df, obj_df):\n",
    "\n",
    "        return pd.concat([obj_df,X_df], axis=1)\n",
    "\n",
    "    def _preprocess_obj_feature(self, obj_df):\n",
    "        #onehot encoding feature\n",
    "        self.encoder1 = OneHotEncoder()\n",
    "        self.encoder1.fit(obj_df)\n",
    "        obj_df = self.encoder1.transform(obj_df)\n",
    "\n",
    "        return obj_df\n",
    "    \n",
    "    def preprocess_target(self, data, index):\n",
    "        return data.loc[index].iloc[:,-28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub_df=pd.read_csv('..\\input\\sample_submission.csv',index_col=0)\n",
    "# sample_sub_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 创建示例 DataFrame\n",
    "# data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "# df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 更改索引标签\n",
    "# new_index_names = {'row1': 'new_row1', 'row2': 'new_row2', 'row3': 'new_row3'}\n",
    "# new_df = df.rename(index=new_index_names)\n",
    "\n",
    "# print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=Dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y_train.columns[dataset.y_train.isna().any()].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30490 entries, HOBBIES_1_001_CA_1_validationtgt_date_0 to FOODS_3_827_WI_3_validationtgt_date_0\n",
      "Columns: 4957 entries, Previous_Day_1885 to state_id_3\n",
      "dtypes: float64(3072), int64(1885)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "# dataset.X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.read_csv('..\\input\\sales_train_evaluation.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id     HOBBIES_1_001\n",
       "dept_id         HOBBIES_1\n",
       "cat_id            HOBBIES\n",
       "store_id             CA_1\n",
       "state_id               CA\n",
       "                ...      \n",
       "d_1937                  0\n",
       "d_1938                  3\n",
       "d_1939                  3\n",
       "d_1940                  0\n",
       "d_1941                  1\n",
       "Name: HOBBIES_1_001_CA_1_evaluation, Length: 1946, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.loc['HOBBIES_1_001_CA_1_evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002_CA_1_evaluation</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003_CA_1_evaluation</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_004_CA_1_evaluation</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_005_CA_1_evaluation</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     item_id    dept_id   cat_id store_id  \\\n",
       "id                                                                          \n",
       "HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "                              state_id  d_1  d_2  d_3  d_4  d_5  ...  d_1932  \\\n",
       "id                                                               ...           \n",
       "HOBBIES_1_001_CA_1_evaluation       CA    0    0    0    0    0  ...       2   \n",
       "HOBBIES_1_002_CA_1_evaluation       CA    0    0    0    0    0  ...       0   \n",
       "HOBBIES_1_003_CA_1_evaluation       CA    0    0    0    0    0  ...       1   \n",
       "HOBBIES_1_004_CA_1_evaluation       CA    0    0    0    0    0  ...       1   \n",
       "HOBBIES_1_005_CA_1_evaluation       CA    0    0    0    0    0  ...       0   \n",
       "\n",
       "                               d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  \\\n",
       "id                                                                              \n",
       "HOBBIES_1_001_CA_1_evaluation       4       0       0       0       0       3   \n",
       "HOBBIES_1_002_CA_1_evaluation       1       2       1       1       0       0   \n",
       "HOBBIES_1_003_CA_1_evaluation       0       2       0       0       0       2   \n",
       "HOBBIES_1_004_CA_1_evaluation       1       0       4       0       1       3   \n",
       "HOBBIES_1_005_CA_1_evaluation       0       0       2       1       0       0   \n",
       "\n",
       "                               d_1939  d_1940  d_1941  \n",
       "id                                                     \n",
       "HOBBIES_1_001_CA_1_evaluation       3       0       1  \n",
       "HOBBIES_1_002_CA_1_evaluation       0       0       0  \n",
       "HOBBIES_1_003_CA_1_evaluation       3       0       1  \n",
       "HOBBIES_1_004_CA_1_evaluation       0       2       6  \n",
       "HOBBIES_1_005_CA_1_evaluation       2       1       0  \n",
       "\n",
       "[5 rows x 1946 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOODS_3_164_CA_4_evaluation</th>\n",
       "      <td>0.983928</td>\n",
       "      <td>2.205954</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>0.907511</td>\n",
       "      <td>1.436865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_198_TX_1_evaluation</th>\n",
       "      <td>1.037716</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.669381</td>\n",
       "      <td>1.008855</td>\n",
       "      <td>1.165628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_1_084_CA_3_evaluation</th>\n",
       "      <td>1.118399</td>\n",
       "      <td>1.315278</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>2.085602</td>\n",
       "      <td>1.436865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_2_180_CA_4_evaluation</th>\n",
       "      <td>1.252869</td>\n",
       "      <td>1.245477</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>0.907511</td>\n",
       "      <td>1.436865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_121_TX_1_evaluation</th>\n",
       "      <td>0.930140</td>\n",
       "      <td>0.347767</td>\n",
       "      <td>0.865138</td>\n",
       "      <td>1.008855</td>\n",
       "      <td>1.165628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_137_WI_3_evaluation</th>\n",
       "      <td>1.091504</td>\n",
       "      <td>2.205954</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>1.070187</td>\n",
       "      <td>1.159615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_117_CA_2_evaluation</th>\n",
       "      <td>1.629387</td>\n",
       "      <td>2.205954</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>1.287635</td>\n",
       "      <td>1.436865</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_1_302_CA_1_evaluation</th>\n",
       "      <td>1.010822</td>\n",
       "      <td>1.365977</td>\n",
       "      <td>0.865138</td>\n",
       "      <td>1.466710</td>\n",
       "      <td>1.436865</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_2_135_TX_2_evaluation</th>\n",
       "      <td>0.957034</td>\n",
       "      <td>0.263758</td>\n",
       "      <td>0.669381</td>\n",
       "      <td>1.273532</td>\n",
       "      <td>1.165628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_087_WI_1_evaluation</th>\n",
       "      <td>1.710070</td>\n",
       "      <td>2.205954</td>\n",
       "      <td>1.806054</td>\n",
       "      <td>1.038373</td>\n",
       "      <td>1.159615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24392 rows × 1918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  item_id   dept_id    cat_id  store_id  \\\n",
       "id                                                                        \n",
       "FOODS_3_164_CA_4_evaluation      0.983928  2.205954  1.806054  0.907511   \n",
       "HOBBIES_1_198_TX_1_evaluation    1.037716  0.814663  0.669381  1.008855   \n",
       "FOODS_1_084_CA_3_evaluation      1.118399  1.315278  1.806054  2.085602   \n",
       "FOODS_2_180_CA_4_evaluation      1.252869  1.245477  1.806054  0.907511   \n",
       "HOUSEHOLD_2_121_TX_1_evaluation  0.930140  0.347767  0.865138  1.008855   \n",
       "...                                   ...       ...       ...       ...   \n",
       "FOODS_3_137_WI_3_evaluation      1.091504  2.205954  1.806054  1.070187   \n",
       "FOODS_3_117_CA_2_evaluation      1.629387  2.205954  1.806054  1.287635   \n",
       "HOUSEHOLD_1_302_CA_1_evaluation  1.010822  1.365977  0.865138  1.466710   \n",
       "HOBBIES_2_135_TX_2_evaluation    0.957034  0.263758  0.669381  1.273532   \n",
       "FOODS_3_087_WI_1_evaluation      1.710070  2.205954  1.806054  1.038373   \n",
       "\n",
       "                                 state_id  d_1  d_2  d_3  d_4  d_5  ...  \\\n",
       "id                                                                  ...   \n",
       "FOODS_3_164_CA_4_evaluation      1.436865    0    0    0    0    0  ...   \n",
       "HOBBIES_1_198_TX_1_evaluation    1.165628    0    0    0    0    0  ...   \n",
       "FOODS_1_084_CA_3_evaluation      1.436865    0    0    0    1    0  ...   \n",
       "FOODS_2_180_CA_4_evaluation      1.436865    0    0    0    0    0  ...   \n",
       "HOUSEHOLD_2_121_TX_1_evaluation  1.165628    0    0    0    0    0  ...   \n",
       "...                                   ...  ...  ...  ...  ...  ...  ...   \n",
       "FOODS_3_137_WI_3_evaluation      1.159615    0    0    0    0    0  ...   \n",
       "FOODS_3_117_CA_2_evaluation      1.436865   15    5    5    5    9  ...   \n",
       "HOUSEHOLD_1_302_CA_1_evaluation  1.436865    0    3    0    1    0  ...   \n",
       "HOBBIES_2_135_TX_2_evaluation    1.165628    0    0    0    0    0  ...   \n",
       "FOODS_3_087_WI_1_evaluation      1.159615    0    0    0    0    0  ...   \n",
       "\n",
       "                                 d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "id                                                                        \n",
       "FOODS_3_164_CA_4_evaluation           0       0       2       0       0   \n",
       "HOBBIES_1_198_TX_1_evaluation         0       1       1       0       0   \n",
       "FOODS_1_084_CA_3_evaluation           1       0       0       0       0   \n",
       "FOODS_2_180_CA_4_evaluation           2       0       1       2       2   \n",
       "HOUSEHOLD_2_121_TX_1_evaluation       0       0       0       0       0   \n",
       "...                                 ...     ...     ...     ...     ...   \n",
       "FOODS_3_137_WI_3_evaluation           0       0       0       1       0   \n",
       "FOODS_3_117_CA_2_evaluation           2       1       1       0       1   \n",
       "HOUSEHOLD_1_302_CA_1_evaluation       3       1       1       0       0   \n",
       "HOBBIES_2_135_TX_2_evaluation         0       0       0       1       0   \n",
       "FOODS_3_087_WI_1_evaluation           1       0       1       0       1   \n",
       "\n",
       "                                 d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "id                                                                       \n",
       "FOODS_3_164_CA_4_evaluation           0       0       0       0       0  \n",
       "HOBBIES_1_198_TX_1_evaluation         0       0       0       1       0  \n",
       "FOODS_1_084_CA_3_evaluation           0       0       0       0       0  \n",
       "FOODS_2_180_CA_4_evaluation           0       0       1       0       1  \n",
       "HOUSEHOLD_2_121_TX_1_evaluation       2       0       0       0       0  \n",
       "...                                 ...     ...     ...     ...     ...  \n",
       "FOODS_3_137_WI_3_evaluation           0       0       0       2       0  \n",
       "FOODS_3_117_CA_2_evaluation           1       1       0       4       2  \n",
       "HOUSEHOLD_1_302_CA_1_evaluation       0       0       0       2       0  \n",
       "HOBBIES_2_135_TX_2_evaluation         1       0       0       0       0  \n",
       "FOODS_3_087_WI_1_evaluation           0       1       2       1       1  \n",
       "\n",
       "[24392 rows x 1918 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    def __init__(self, is_load=False, load_path='models'):\n",
    "        '''\n",
    "\n",
    "\n",
    "        '''\n",
    "        \n",
    "        package_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "        self.model_path = os.path.join(package_dir,load_path)\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        \n",
    "        if is_load:\n",
    "            self._load_models(load_path)\n",
    "        else:\n",
    "            self._set_28_models()\n",
    "\n",
    "    # def _create_pipe(self, X_train):\n",
    "    #     return make_pipeline(\n",
    "    #         TargetEncoder(cols=X_train.columns[X_train.dtypes == 'object'],\n",
    "    #                       handle_missing='return_nan'),\n",
    "    #         SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    #         XGBRegressor()\n",
    "    #     )\n",
    "    def _load_models(self,load_path):\n",
    "        \n",
    "        self.models = [joblib.load(os.path.join(self.model_path, fn))\n",
    "                        for fn in sorted(os.listdir(self.model_path))]\n",
    "\n",
    "    def _set_28_models(self):\n",
    "        self.models=[]\n",
    "        for i in range(28):\n",
    "            self.models.append(XGBRegressor())\n",
    "\n",
    "    def _train_28_models(self, X_train, X_local_val, y_train, y_local_val):\n",
    "        for i in range(28):\n",
    "            \n",
    "            # from IPython import embed\n",
    "            # embed()\n",
    "            self.models[i].fit(X_train, y_train.iloc[:,i])\n",
    "            self.models[i]\n",
    "            y_pred = self.models[i].predict(X_local_val)\n",
    "            # 計算均方根誤差\n",
    "            mse = mean_squared_error(y_local_val.iloc[:,i], y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            print(\"mse:\",mse,\"     Root Mean Squared Error:\", rmse)\n",
    "            joblib.dump(self.models[i], os.path.join(\n",
    "                self.model_path, f\"model_day{str(i).zfill(2)}.pkl\"), compress=3)\n",
    "    def models_predict(self, X_val:pd.DataFrame, name='result_simple.csv'):\n",
    "\n",
    "        output = X_val.iloc[:,0:1]\n",
    "        for i in range(28):\n",
    "            val_data_tmp_y = self.models[i].predict(X_val)\n",
    "            output[f'F{i+1}'] = val_data_tmp_y\n",
    "\n",
    "        output=output.iloc[:,1:]\n",
    "        output.to_csv(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=Models()\n",
    "#519 17 5.429\n",
    "#526 18 4.6\n",
    "7*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 3.990953347658384      Root Mean Squared Error: 1.997737056686486\n",
      "mse: 3.3281554476279838      Root Mean Squared Error: 1.8243232848450912\n",
      "mse: 3.5347837656356518      Root Mean Squared Error: 1.8801020625582143\n",
      "mse: 3.5707828792865652      Root Mean Squared Error: 1.8896515232408766\n",
      "mse: 4.272832285142021      Root Mean Squared Error: 2.067083037795536\n",
      "mse: 6.065101025823118      Root Mean Squared Error: 2.4627425821273157\n",
      "mse: 5.847492370514349      Root Mean Squared Error: 2.4181588803290714\n",
      "mse: 4.916139024465091      Root Mean Squared Error: 2.2172367993665203\n",
      "mse: 5.17350803931068      Root Mean Squared Error: 2.2745346863283222\n",
      "mse: 4.735847066677701      Root Mean Squared Error: 2.1762001439843948\n",
      "mse: 4.425248772990128      Root Mean Squared Error: 2.103627527151641\n",
      "mse: 5.869327747565556      Root Mean Squared Error: 2.4226695498077233\n",
      "mse: 6.401975257870526      Root Mean Squared Error: 2.5302124926318985\n",
      "mse: 5.931856193455615      Root Mean Squared Error: 2.435540226203545\n",
      "mse: 5.5797222183972135      Root Mean Squared Error: 2.3621435643070496\n",
      "mse: 4.42079527556919      Root Mean Squared Error: 2.1025687326623093\n",
      "mse: 5.4291035980752556      Root Mean Squared Error: 2.330043690164469\n",
      "mse: 4.609532467841316      Root Mean Squared Error: 2.146982176880217\n",
      "mse: 5.172698576810662      Root Mean Squared Error: 2.2743567391266177\n",
      "mse: 7.008993577114759      Root Mean Squared Error: 2.6474503918137464\n",
      "mse: 8.603923246195988      Root Mean Squared Error: 2.9332444913774216\n",
      "mse: 4.8341576735161      Root Mean Squared Error: 2.1986717975896495\n",
      "mse: 4.007312936674788      Root Mean Squared Error: 2.001827399321627\n",
      "mse: 3.8153544966598063      Root Mean Squared Error: 1.953293243898572\n",
      "mse: 4.09243575654989      Root Mean Squared Error: 2.0229769540333105\n",
      "mse: 4.406945997007207      Root Mean Squared Error: 2.0992727304967325\n",
      "mse: 5.929323404086537      Root Mean Squared Error: 2.4350202060940966\n",
      "mse: 6.350285837240968      Root Mean Squared Error: 2.519977348557119\n"
     ]
    }
   ],
   "source": [
    "models._train_28_models(dataset.X_train,dataset.X_val,dataset.y_train,dataset.y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dataset.X_test.iloc[:,0:1]\n",
    "for i in range(28):\n",
    "    val_data_tmp_y = models.models[i].predict(dataset.X_test)\n",
    "    output[f'F{i+1}'] = val_data_tmp_y\n",
    "\n",
    "output=output.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('result_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = val_data.x.iloc[:,0:1]\n",
    "for i in range(28):\n",
    "    val_data_tmp_y = models.models[i].predict(val_data.x)\n",
    "    output[f'F{i+1}'] = val_data_tmp_y\n",
    "\n",
    "output=output.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_result=pd.concat([val_data.sales.iloc[:,0], output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_result.to_csv('first_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9999541e-01, 8.9999714e+00, 1.9999998e+00, ..., 9.9999541e-01,\n",
       "       4.2390134e-06, 4.2390134e-06], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.models[0].predict(train_data.X_local_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2404     1\n",
       "7576     9\n",
       "8731     2\n",
       "4756     1\n",
       "15509    0\n",
       "        ..\n",
       "8870     0\n",
       "1423     0\n",
       "27492    1\n",
       "27020    0\n",
       "21011    0\n",
       "Name: d_1914, Length: 6098, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.y_local_val.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_local_val[:,i], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.models[0].predict(train_data.X_local_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=Models(is_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.models_predict(dataset.X_test, name='result2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11535    0\n",
       "12387    0\n",
       "7792     0\n",
       "11153    2\n",
       "13413    0\n",
       "        ..\n",
       "29802    0\n",
       "5390     0\n",
       "860      1\n",
       "15795    0\n",
       "23654    1\n",
       "Name: d_1914, Length: 24392, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.y_train.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   A       3 non-null      int64 \n",
      " 1   B       3 non-null      object\n",
      " 2   C       3 non-null      bool  \n",
      "dtypes: bool(1), int64(1), object(1)\n",
      "memory usage: 179.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A      C\n",
      "0  1   True\n",
      "1  2  False\n",
      "2  3   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建示例DataFrame\n",
    "data = {'A': [1, 2, 3], 'B': ['foo', 'bar', 'baz'], 'C': [True, False, True]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 获取所有物件类型的列\n",
    "object_columns = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "# 打印列名\n",
    "print(df[object_columns])\n",
    "# 这将打印出DataFrame中所有物件类型的列名。你可以根据需要使用这些列名进行进一步的操作，例如筛选特定的列或进行其他数据处理。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_data.sales.index:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class model:\n",
    "    def __init__(self, load=False):\n",
    "\n",
    "\n",
    "        package_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        self.model_path = os.path.join(\n",
    "            package_dir, f'./models/')\n",
    "\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "\n",
    "        if load:\n",
    "            self.models = [joblib.load(os.path.join(self.model_path, fn))\n",
    "                           for fn in sorted(os.listdir(self.model_path))]\n",
    "        else:\n",
    "            for fn in os.listdir(self.model_path):\n",
    "                os.remove(os.path.join(self.model_path, fn))\n",
    "            self.models = []\n",
    "            self._train_inference = None\n",
    "            self._train_27_models()\n",
    "\n",
    "    def _create_pipe(self, X_train):\n",
    "        return make_pipeline(\n",
    "            TargetEncoder(cols=X_train.columns[X_train.dtypes == 'object'],\n",
    "                          handle_missing='return_nan'),\n",
    "            SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "            XGBRegressor()\n",
    "        )\n",
    "    def _train_27_models(self):\n",
    "        for i in range(1, 28):\n",
    "            train = self._create_label(\"train\", i)\n",
    "            x_train, y_train = train.drop(\n",
    "                self.cols_dropped, axis=1), train.警示數量\n",
    "            # from IPython import embed\n",
    "            # embed()\n",
    "            model = self._create_pipe(x_train)\n",
    "            model.fit(x_train, y_train)\n",
    "            joblib.dump(model, os.path.join(\n",
    "                self.model_path, f\"{datetime.now().date()}_w{str(i).zfill(2)}.pkl\"), compress=3)\n",
    "            self.models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_booster().get_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
